{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 More evolutionary and advanced considerations\n",
    "\n",
    "\n",
    "## Multiple Scores\n",
    "## Population of results/estimates\n",
    "## Population diversity\n",
    "## On the fly learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first chunk of code is boilerplate, as usual, just more can be considered boilerplate now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boilerplate python and reading in data\n",
    "import sys\n",
    "import csv\n",
    "from math import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Particular to the evolution\n",
    "from scores import *\n",
    "from evolution3 import *\n",
    "\n",
    "# Some global parameters:\n",
    "nobs = 579\n",
    "nparameters = 6\n",
    "\n",
    "npopulation = 10\n",
    "per_second = 60     # estimate of number of generations per second\n",
    "genmax = int(60*per_second)\n",
    "\n",
    "train_start = int(0)\n",
    "train_end   = int(364)\n",
    "np.random.seed(0)      # for reproducibility\n",
    "\n",
    "######################## ######################## ########################\n",
    "# Now bring in the data for real work:\n",
    "matchup_set = []\n",
    "\n",
    "with open('testin.csv') as csvfile:\n",
    "    k = 0\n",
    "    sreader = csv.reader(csvfile, delimiter=\",\")\n",
    "    for line in sreader:\n",
    "        day     = float(line[0])\n",
    "        t2m_gfs = float(line[1])\n",
    "        td_gfs  = float(line[2])\n",
    "        thick_gfs = float(line[3])\n",
    "        rh_gfs  = float(line[4])\n",
    "        speed   = float(line[5])\n",
    "        obs_t2m = float(line[6])\n",
    "        obs_td  = float(line[7])\n",
    "        terr    = float(line[8])\n",
    "        tderr  = float(line[9])\n",
    "\n",
    "        #Note that obs_td, obs_t2m, tderr are being ignored. They can be\n",
    "        #       added to the list.\n",
    "        #  n.b.: note that it is terr that is used, not t2m itself.\n",
    "        #Model and observation are well-enough correlated that it is the increment\n",
    "        #which makes more sense to predict [Krasnopolsky,20NNN]\n",
    "        m = matchup((day,t2m_gfs,td_gfs,thick_gfs,rh_gfs,speed,terr))\n",
    "        matchup_set.append(m)\n",
    "        k += 1\n",
    "\n",
    "csvfile.close()\n",
    "######################## ######################## ########################\n",
    "\n",
    "#Initialize and seed the population, best, and good\n",
    "population = []\n",
    "bests      = []       # Save all then-best versions in memory\n",
    "goods      = []       # Save everything better than raw GFS to file (could be a lot)\n",
    "fgood = open(\"goods\",\"w\")\n",
    "\n",
    "for k in range (0,npopulation):\n",
    "    population.append(critter(nparameters))\n",
    "\n",
    "weights = np.zeros((nparameters))\n",
    "sdevs   = np.zeros((nparameters))\n",
    "\n",
    "bests.append(critter(nparameters))\n",
    "bests[0].init(weights, sdevs, 99.)\n",
    "nbests = 1\n",
    "\n",
    "goods.append(critter(nparameters))\n",
    "goods[0].init(weights, sdevs, 99.)\n",
    "ngoods = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you go to the 'home' screen, you'll see that the file 'goods' now exists.\n",
    "\n",
    "Now ready to start looking in to our more advanced topics, starting with\n",
    "\n",
    "## 2 Multiple scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this and re-run to see the effects of changes to the metric used:\n",
    "#  Options are:\n",
    "#  RMS (default)\n",
    "#  MEAN\n",
    "#  RM3 (root mean cubed error, will be related to skew)\n",
    "#  RM4 (root mean quartic error, will be related to kurtosis)\n",
    "#  MAE (Mean absolute error)\n",
    "#  NLOSS (count the number of times the corrected output is worse than the original); \n",
    "#      not currently working, will fall back to RMS\n",
    "#  VICKIE (MAE with a 3 C tolerance -- errors less than 3 C are ignored, otherwise, MAE)\n",
    "#    -- a representation of a real person's (my wife) interest in T2M accuracy.\n",
    "#The 'scores' file imported above contains the code and it is easy to add or modify\n",
    "\n",
    "#We could also make this a loop itself, and would outside of a notebook. \n",
    "#  But, in notebook, let's take advantage of the interactive nature.\n",
    "#  Try also, at least, MEAN and MAE\n",
    "measure = RMS\n",
    "\n",
    "#for reference, take the raw gfs output's score:\n",
    "population[0].init(weights, sdevs, 99.)\n",
    "score_gfs = population[0].skill(matchup_set, train_start, train_end, metric = measure)\n",
    "\n",
    "print(\"uncorrected score in training period: \",\n",
    "         population[0].skill(matchup_set, train_start, train_end, metric = measure) )\n",
    "print(\"uncorrected score in evaluation period: \",\n",
    "         population[0].skill(matchup_set, train_end+1, nobs, metric = measure), flush=True )\n",
    "population[0].show_fcst(matchup_set, train_start, train_end)\n",
    "print(\"\\n\",flush=True)\n",
    "\n",
    "#For bias + linear terms\n",
    "for k in range (0,int(6)):\n",
    "    sdevs[k] = 1.0\n",
    "\n",
    "#Initialize the population\n",
    "for k in range (0,npopulation):\n",
    "  for l in range (0, int(6) ):  \n",
    "      weights[l] = np.random.normal(0,sdevs[l])\n",
    "  population[k].init(weights,sdevs, 99.)\n",
    "\n",
    "#Find our first 'best' -- noting that we aren't using raw gfs as a member of the population\n",
    "smin = 9999.\n",
    "kbest = int(npopulation)\n",
    "for k in range (0,npopulation):\n",
    "    population[k].skill(matchup_set, train_start, train_end, metric = measure)\n",
    "    if (population[k].score < smin):\n",
    "        kbest = k\n",
    "        smin = population[k].score\n",
    "\n",
    "#Start accumulating our best critters\n",
    "bests.append(critter(nparameters))\n",
    "bests[nbests].init(population[kbest].weights, population[kbest].sdevs, population[kbest].score)\n",
    "nbests += 1\n",
    "\n",
    "# ... and ones better than raw gfs\n",
    "if (smin < score_gfs):\n",
    "    goods.append(critter(nparameters))\n",
    "    goods[ngoods].init(population[kbest].weights, population[kbest].sdevs, population[kbest].score)\n",
    "    ngoods += 1\n",
    "\n",
    "population[kbest].show()\n",
    "print(\"initial kbest, smin = \",kbest, smin, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, now run through the generations. But this time, save all the 'good' parameter settings, not just the best. We'll examine them for ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen in range(0,genmax):\n",
    "    if ((gen%per_second) == 0):\n",
    "        print(\"generation \", gen, flush=True)\n",
    "\n",
    "    population[0].copy(population[kbest])\n",
    "    population[0].score = population[kbest].score\n",
    "    score_best = float(population[0].score)\n",
    "    smin = score_best\n",
    "    kbest = 0\n",
    "    for k in range (1, npopulation):\n",
    "        population[k].copy(population[0])\n",
    "        population[k].evolve()\n",
    "        population[k].skill(matchup_set, train_start, train_end, metric = RMS)\n",
    "        if (population[k].score < score_best):\n",
    "            kbest = k\n",
    "            smin = population[k].score\n",
    "            bests.append(critter(nparameters))\n",
    "            bests[nbests].init(population[kbest].weights, population[kbest].sdevs, population[kbest].score)\n",
    "            nbests += 1\n",
    "        #Save the ones that are better than the raw gfs\n",
    "        if (population[k].score < score_gfs):\n",
    "            kgood = k\n",
    "            goods.append(critter(nparameters))\n",
    "            goods[ngoods].score = population[k].score\n",
    "            goods[ngoods].init(population[kgood].weights, population[kgood].sdevs, population[k].score)\n",
    "            population[k].show(fgood)  #Print this 'good' result to file for safe-keeping\n",
    "            ngoods += 1\n",
    "\n",
    "    if (kbest != 0):\n",
    "        if (score_gfs != 0):\n",
    "          print(\"new best \",gen, kbest, smin, score_best, smin/score_gfs, flush=True)\n",
    "        else:\n",
    "          print(\"new best \",gen, kbest, smin, score_best, flush=True)\n",
    "        population[kbest].show()\n",
    "        \n",
    "print(\"done with generations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## ######################## ########################\n",
    "if (score_gfs != 0):\n",
    "  print(\"best score in training period \",gen, kbest, smin, score_best, smin/score_gfs, flush=True)\n",
    "else:\n",
    "  print(\"best score in training period \",gen, kbest, smin, score_best, flush=True)\n",
    "print(\"score in the untrained period: \",population[kbest].skill(matchup_set, train_end+1, nobs, metric = measure))\n",
    "\n",
    "print(\"found \",ngoods,\" good solutions\")\n",
    "\n",
    "for k in range (0, nbests):\n",
    "  print(\"best k \",k,bests[k].score)\n",
    "  bests[k].show()\n",
    "  print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Forecasts in the training period:\")\n",
    "population[0].show_fcst(matchup_set, train_start, train_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Untrained forecasts:\")\n",
    "population[0].show_fcst(matchup_set, train_end, nobs)\n",
    "population[0].skill(matchup_set, train_end+1, nobs, metric = measure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considering different scores:\n",
    "\n",
    "(warning, I may have failed to properly re-initialize metrics, this is place holder text, not finished)\n",
    "\n",
    "### After optimizing for RMS:\n",
    "trained period has 44% the RMS of raw GFS (16.79)\n",
    "\n",
    "trained mean rms  -0.1532608638628728 7.452270353231618  (44%)\n",
    "\n",
    "raw gfs training period mean rms  13.939368131868132 16.79408375517474\n",
    "\n",
    "untrained mean rms  -1.6085981736055173 5.385852764158143\n",
    "\n",
    "raw gfs untrained period: 11.899786904482491 \n",
    "\n",
    "\n",
    "### Optimizing for MAE\n",
    "uncorrected score in training period:  14.072794520547944\n",
    "\n",
    "uncorrected score in evaluation period:  10.25293023255814\n",
    "\n",
    "best score in training period  3599 0 7.451589648287305 7.451589648287305 0.5295031940818224\n",
    "\n",
    "trained mean rms  2.3770208862705613 9.513703004818282\n",
    "\n",
    "score in the untrained period:  4.331689063263931\n",
    "\n",
    "untrained mean rms  0.946926616881068 5.606120899560049\n",
    "\n",
    "### Optimizing for Vickie\n",
    "uncorrected score in training period:  15.619538461538465\n",
    "\n",
    "uncorrected score in evaluation period:  11.043857868020302\n",
    "\n",
    "trained mean rms  -0.1532608638628728 7.452270353231618 #### note same as for RMS\n",
    "\n",
    "best score in training period  3599 0 7.442054761927269 7.442054761927269 0.4764580451754433\n",
    "\n",
    "untrained mean rms  -1.6085981736055173 5.385852764158143\n",
    "\n",
    "untrained score in evaluation period: 6.169421042958432\n",
    "\n",
    "\n",
    "### Optimizing for Mean\n",
    "uncorrected score in training period:  13.901178082191784\n",
    "\n",
    "uncorrected score in evaluation period:  10.209953488372092\n",
    "\n",
    "best score in training period  3599 0 2.3705085002807773 2.3705085002807773 0.17052572711931058\n",
    "\n",
    "score in the untrained period:  0.9707819312466325\n",
    "\n",
    "\n",
    "### Optimizing for RM4\n",
    "\n",
    "uncorrected score in training period:  20.17958780895671\n",
    "\n",
    "uncorrected score in evaluation period:  14.35790534535554\n",
    "\n",
    "best score in training period  3599 0 7.442054761927269 7.442054761927269 0.3687912177583782\n",
    "\n",
    "trained mean rms  -0.1532608638628728 7.452270353231618\n",
    "\n",
    "untrained mean rms  -1.6085981736055173 5.385852764158143\n",
    "\n",
    "score in the untrained period:  7.567201668271535"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking in to the nature of the 'good' results\n",
    "\n",
    "We now have a large number (typically a few thousand, for a population of 10 per generation and 3600 generations) of parameter sets / regression coefficients, and the (training period) score for them. In the case of a typical regression, we would be done here.\n",
    "\n",
    "As an evolutionary matter, we have more that we may examine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the weights and the skill in the training set that corresponded to good results\n",
    "#print(ngoods, nparameters)\n",
    "\n",
    "consts = np.zeros((ngoods, nparameters))\n",
    "skill = np.zeros((ngoods))\n",
    "\n",
    "for i in range(0,ngoods):\n",
    "# Both this and the commented-out segment work, but this is more pythonic\n",
    "    consts[i] = goods[i].weights\n",
    "#    for k in range (0,nparameters):\n",
    "#        consts[i,k] = goods[i].weights[k]\n",
    "    skill[i]  = goods[i].score\n",
    "\n",
    "print(skill.min(), skill.mean(), len(skill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the coefficients for T2m and Td in the regression\n",
    "fig,ax = plt.subplots()\n",
    "ax.set(xlabel=\"GFS T2m coefficient\", ylabel=\"GFS Td coefficient\")\n",
    "ax.scatter(consts[:,1],consts[:,2])\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Masked array support, so we can work with selected parts of the arrays/vectors\n",
    "import numpy.ma as ma\n",
    "\n",
    "good1 = np.zeros((ngoods))\n",
    "good2 = np.zeros((ngoods))\n",
    "\n",
    "# Since we know the minimum and mean scores, try plotting only those points for which the \n",
    "#    score is better than the mean\n",
    "mask1 = ma.masked_array(skill < (skill.mean() + skill.min())/2. )\n",
    "tcount = 0\n",
    "for i in range(0,ngoods):\n",
    "    if (mask1[i]):\n",
    "        #print(skill[i])\n",
    "        good1[i] = consts[i,1]\n",
    "        good2[i] = consts[i,2]\n",
    "        tcount += 1\n",
    "        \n",
    "print(\"found \",tcount,\" points\")\n",
    "# Take a look at the coefficients for T2m and Td in the regression\n",
    "fig,ax = plt.subplots()\n",
    "ax.set(xlabel=\"GFS T2m coefficient\", ylabel=\"GFS Td coefficient\")\n",
    "ax.scatter(good1, good2)\n",
    "ax.grid()\n",
    "plt.show()    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try overlaying the better coefficients against all that were 'good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set(xlabel=\"GFS T2m coefficient\", ylabel=\"GFS Td coefficient\")\n",
    "ax.scatter(consts[:,1],consts[:,2], color = \"black\")\n",
    "ax.scatter(good1, good2, color = \"blue\")\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try for the 'very good' coefficients, those within 10% of the best (vs best-gfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgood1 = np.zeros((ngoods))\n",
    "vgood2 = np.zeros((ngoods))\n",
    "\n",
    "# Since we know the minimum and mean scores, try plotting only those points for which the \n",
    "#    score is better than the mean\n",
    "mask2 = ma.masked_array(skill < (skill.min() + (score_gfs - skill.min())*0.1 ))\n",
    "tcount2 = 0\n",
    "for i in range(0,ngoods):\n",
    "    if (mask2[i]):\n",
    "        #print(skill[i])\n",
    "        vgood1[i] = consts[i,1]\n",
    "        vgood2[i] = consts[i,2]\n",
    "        tcount2 += 1\n",
    "        \n",
    "print(\"found \",tcount2,\" points\")\n",
    "print(vgood2.min())\n",
    "                        \n",
    "fig, ax = plt.subplots()\n",
    "ax.set(xlabel=\"GFS T2m coefficient\", ylabel=\"GFS Td coefficient\")\n",
    "ax.scatter(consts[:,1],consts[:,2], color = \"black\")\n",
    "ax.scatter(good1, good2, color = \"blue\")\n",
    "ax.scatter(vgood1, vgood2, color = \"red\")\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerations:\n",
    "\n",
    "We see a definite progression, in that the better (lower) a score we require, the tighter a cloud that is found. On the other hand, the GFS T2m coefficient has quite a large allowable range -- from -1 to +1, while the GFS Td coefficient has an even larger range -- 0 to -3. Optically, at least, there's a very strong suggestion that the thing which is important is not T2m or Td, but, the difference between the two. Maybe a linear function of the difference, since the slope looks more like 1.5 than 1.\n",
    "\n",
    "Is there a geophysical process or phenomenon that would depend on the difference between T2m and Td? The one that occurs to me is radiation from the surface layer. A drier atmosphere will be different than a wetter one regarding outgoing longwave, or, perhaps (via low level clouds) shortwave.\n",
    "\n",
    "Simple-minded use of multiple regression could miss this. Our rather simple consideration from an evolutionary method catches this relation that can be used for further model diagnostics -- not just the correction of model output.\n",
    "\n",
    "In the evolutionary method, we could now make (GFS T2m-Td) one of the variables used, directly, in the prediction, and its coefficient would be one of those we ask evolution to discover for us. Further, if we had reason (say because we, the some of we who are not me, understand radiative transfer well enough) to take a particular nonlinear function of T2m and Td, we could ask the evolutionary method to find _that_ function's parameters. \n",
    "\n",
    "Most simply, we could add a 7th parameter to our weights and standard deviations set, and make that the coefficient of (GFS T2m-td) in the predictor. Absolutely no meaningful change to the main program (nparameters has to be changed), just in the predictor code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
